{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMu0/syX3wQ7rBlmOYvf0NE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Theoretical**"],"metadata":{"id":"yBZTPOS-VRo1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cK4vQfANK37w"},"outputs":[],"source":["### Q.1) What is Logistic Regression, and how does it differ from Linear Regression?"]},{"cell_type":"code","source":["ans) Logistic Regression is a statistical method used for binary classification. Unlike Linear Regression, which predicts continuous values, Logistic Regression predicts probabilities that are mapped to binary outcomes using the sigmoid function.\n","\n"],"metadata":{"id":"_ZtpJpS7K4cI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.2) What is the mathematical equation of Logistic Regression?"],"metadata":{"id":"RjbBGpB6K4f_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans)  Equation of Logistic Regression:\n","                    The logistic regression equation consists of two main parts:\n","\n","The linear predictor (z):\n","z = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ\n","where:\n","\n","β₀ is the intercept\n","β₁ to βₙ are the coefficients\n","x₁ to xₙ are the input features\n","\n","\n","The logistic (sigmoid) function:\n","P(y=1|x) = 1 / (1 + e⁻ᶻ)\n","where:\n","\n","P(y=1|x) is the probability of the positive class given inputs x\n","e is Euler's number (approximately 2.71828)\n","z is the linear predictor from step 1\n","\n","\n","\n","Combining these, the complete equation is:\n","P(y=1|x) = 1 / (1 + e⁻⁽β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ⁾)"],"metadata":{"id":"_CzRvavUK4jf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.3) Why do we use the Sigmoid function in Logistic Regression?"],"metadata":{"id":"rz3bIkwbK4mX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) The sigmoid function maps real-valued inputs to a range between 0 and 1, making it suitable for probability estimation in binary classification."],"metadata":{"id":"DbcIxVysK4p2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.4) What is the cost function of Logistic Regression?"],"metadata":{"id":"2Gm9oNhxK4s-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) The cost function for logistic regression is called the \"Binary Cross-Entropy\" or \"Log Loss\" function. For a single training example, it is:\n","J(θ) = -[y log(h_θ(x)) + (1-y)log(1-h_θ(x))]\n","where:\n","\n","J(θ) is the cost function\n","y is the actual label (0 or 1)\n","h_θ(x) is the predicted probability P(y=1|x)\n","log is the natural logarithm\n","\n","For an entire training set of m examples, the cost function becomes:\n","J(θ) = -(1/m) ∑[y⁽ⁱ⁾log(h_θ(x⁽ⁱ⁾)) + (1-y⁽ⁱ⁾)log(1-h_θ(x⁽ⁱ⁾))]\n","where:\n","\n","m is the number of training examples\n","i represents each training example"],"metadata":{"id":"nBqoweBjK4xz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.5) What is Regularization in Logistic Regression? Why is it needed?"],"metadata":{"id":"VWToi9zWK4zP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) Regularization prevents overfitting by adding a penalty to the loss function. It helps in controlling the model complexity and improving generalization."],"metadata":{"id":"jNTkdABlK42f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.6) Explain the difference between Lasso, Ridge, and Elastic Net regression."],"metadata":{"id":"-K0gqT22K5v_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) 1)  Lasso (L1 Regularization): Shrinks coefficients and performs feature selection.\n","2) Ridge (L2 Regularization): Shrinks coefficients but does not eliminate any.\n","3) Elastic Net: A combination of L1 and L2 regularization.\n"],"metadata":{"id":"3HGZzsCuK5zI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.7) When should we use Elastic Net instead of Lasso or Ridge?"],"metadata":{"id":"Yi6IHDuRK52P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) Elastic Net is used when there are highly correlated features because it combines the benefits of Lasso (feature selection) and Ridge (coefficient shrinkage).\n","\n"],"metadata":{"id":"nybItdi9K55n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.8) What is the impact of the regularization parameter (λ) in Logistic Regression?"],"metadata":{"id":"-4uzT-KPK58_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) The regularization parameter (λ) in logistic regression controls the strength of regularization. Higher values of λ lead to stronger regularization."],"metadata":{"id":"sUYvRYQTK6AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.9) What are the key assumptions of Logistic Regression?"],"metadata":{"id":"8vq3SRNPK6Ef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) 1) The dependent variable is binary.\n","2) The independent variables have little multicollinearity.\n","3) The independent variables have a linear relationship with the log-odds.\n"],"metadata":{"id":"-KJCMSDbK6JP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.10) What are some alternatives to Logistic Regression for classification tasks?"],"metadata":{"id":"RCdibKN0K6Mh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) 1) Decision Trees\n","2) Support Vector Machines (SVM)\n","3) Random Forest\n","4) Neural Networks\n","5) Naive Bayes"],"metadata":{"id":"TaqLf_vpK6QY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.11) What are Classification Evaluation Metrics?"],"metadata":{"id":"LxulgEQLK6Tw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) 1) Accuracy\n","2) Precision\n","3) Recall\n","4) F1-score\n","5) ROC-AUC"],"metadata":{"id":"gs81UKUJK6X_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.12) How does class imbalance affect Logistic Regression?"],"metadata":{"id":"0edkBqaiLfIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) It can cause the model to favor the majority class, leading to poor performance. Techniques like oversampling, undersampling, or using weighted loss functions can help."],"metadata":{"id":"PUiOYc0YLffP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.13) What is Hyperparameter Tuning in Logistic Regression?"],"metadata":{"id":"wNJyNSSkLf5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) Hyperparameter tuning involves optimizing parameters like C (inverse of regularization strength), solver, and penalty (L1, L2, Elastic Net) to improve model"],"metadata":{"id":"rzCS4jAaLgcH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.14) What are different solvers in Logistic Regression? Which one should be used?"],"metadata":{"id":"BJXAeKyKLiGX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) 1) liblinear: Works well for small datasets and supports L1/L2 regularization.\n","2) saga: Suitable for large datasets and supports all types of regularization.\n","3) newton-cg, lbfgs: Suitable for larger datasets and only supports L2 regularization."],"metadata":{"id":"VMUVZ-4aLiBg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.15) How is Logistic Regression extended for multiclass classification?"],"metadata":{"id":"VrQoFL4jLh9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans)1)  One-vs-Rest (OvR): Trains multiple binary classifiers.\n","2) Softmax Regression: Uses a generalized logistic function to assign probabilities across multiple classes."],"metadata":{"id":"FT89rH8FLh6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.16) What are the advantages and disadvantages of Logistic Regression?\n"],"metadata":{"id":"ChsO9bbQLh0X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) Advantages:\n","\n","Easy to implement and interpret.\n","Works well for linearly separable data.\n","Disadvantages:\n","Struggles with non-linearly separable data.\n","Sensitive to outliers."],"metadata":{"id":"l3rvkqMHLhvP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.17) What are some use cases of Logistic Regression?"],"metadata":{"id":"wyrtBwo4Lhnx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) 1) Spam detection\n","2) Disease diagnosis\n","3) Customer churn prediction\n","4) Credit scoring"],"metadata":{"id":"uHZ2__kLLhkP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.18) What is the difference between Softmax Regression and Logistic Regression?"],"metadata":{"id":"inmM23nlLhgX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) 1) Logistic Regression is for binary classification, while Softmax Regression is for multiclass classification.\n","2) Softmax assigns probabilities to multiple classes summing to 1."],"metadata":{"id":"ZKdmQefnLhZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.19) How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?"],"metadata":{"id":"TAyRtod3LhM_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans)1)  OvR: Works well for small datasets and is easier to train.\n","2)  Softmax: Preferred when performance and probabilistic interpretation are required."],"metadata":{"id":"aVQaPoLhLg9_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.20) How do we interpret coefficients in Logistic Regression?"],"metadata":{"id":"hwbMpCsGL7bP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) The coefficients represent the log-odds change for a unit increase in the predictor variable. Exponentiating the coefficients gives the odds ratio.\n","\n"],"metadata":{"id":"hWkIFLXvL7RP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Practical**"],"metadata":{"id":"0cjyeaKkQGCA"}},{"cell_type":"code","source":["### Q.1)  Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy."],"metadata":{"id":"VZOB5IaaQKvg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans)  from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.datasets import load_iris\n","\n","# Load dataset\n","data = load_iris()\n","X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n","\n","# Train Logistic Regression model\n","model = LogisticRegression(max_iter=200)\n","model.fit(X_train, y_train)\n","\n","# Predict and evaluate\n","y_pred = model.predict(X_test)\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"id":"yPW78kR8QnF4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.2) Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy."],"metadata":{"id":"liQgHGpCQm-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=200)\n","model.fit(X_train, y_train)\n","\n","# Predict and evaluate\n","y_pred = model.predict(X_test)\n","print(\"L1 Regularization Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"id":"8iuTFqdFQm1A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.3) Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients."],"metadata":{"id":"fl-OMr3UQmyi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans)  model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200)\n","model.fit(X_train, y_train)\n","\n","# Predict and evaluate\n","y_pred = model.predict(X_test)\n","print(\"L2 Regularization Accuracy:\", accuracy_score(y_test, y_pred))\n","\n","# Print coefficients\n","print(\"Coefficients:\", model.coef_)\n"],"metadata":{"id":"LyimTrImQmvL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.4) Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."],"metadata":{"id":"YUtnDwwLQmr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=200)\n","model.fit(X_train, y_train)\n","\n","# Predict and evaluate\n","y_pred = model.predict(X_test)\n","print(\"Elastic Net Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"id":"RfQpQ6f2QmoY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.5)   Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'."],"metadata":{"id":"DKtBtjM7Qmla"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans)  model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)\n","model.fit(X_train, y_train)\n","\n","# Predict and evaluate\n","y_pred = model.predict(X_test)\n","print(\"Multiclass (OvR) Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"id":"5zFvV7HwQmia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.6) Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy."],"metadata":{"id":"S5FC1j48Qmeo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\n","    'C': [0.01, 0.1, 1, 10],\n","    'penalty': ['l1', 'l2'],\n","    'solver': ['liblinear']\n","}\n","\n","grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","\n","print(\"Best parameters:\", grid.best_params_)\n","print(\"Best accuracy:\", grid.best_score_)\n"],"metadata":{"id":"7i8ygFW0QmZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.7) Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy."],"metadata":{"id":"-K3iiX4uQmWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.model_selection import StratifiedKFold, cross_val_score\n","\n","skf = StratifiedKFold(n_splits=5)\n","model = LogisticRegression(max_iter=200)\n","scores = cross_val_score(model, X_train, y_train, cv=skf)\n","\n","print(\"Average accuracy:\", scores.mean())\n"],"metadata":{"id":"Z7VxIE5UQmTS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.8) Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."],"metadata":{"id":"N8Z4DOeqQmQL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) import pandas as pd\n","\n","# Load dataset\n","df = pd.read_csv(\"dataset.csv\")\n","\n","# Assuming the last column is the target variable\n","X = df.iloc[:, :-1]\n","y = df.iloc[:, -1]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train Logistic Regression model\n","model = LogisticRegression(max_iter=200)\n","model.fit(X_train, y_train)\n","\n","# Predict and evaluate\n","y_pred = model.predict(X_test)\n","print(\"CSV Dataset Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"id":"ZGT55ef8QmNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.9) Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy."],"metadata":{"id":"gyWjtyszQmAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.model_selection import RandomizedSearchCV\n","import numpy as np\n","\n","param_dist = {\n","    'C': np.logspace(-3, 3, 10),\n","    'penalty': ['l1', 'l2'],\n","    'solver': ['liblinear']\n","}\n","\n","random_search = RandomizedSearchCV(LogisticRegression(max_iter=200), param_distributions=param_dist, cv=5, n_iter=10, random_state=42)\n","random_search.fit(X_train, y_train)\n","\n","print(\"Best parameters:\", random_search.best_params_)\n","print(\"Best accuracy:\", random_search.best_score_)\n"],"metadata":{"id":"vpN_C1BOR6eB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.10) Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy."],"metadata":{"id":"za2IfMBWR6aZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.multiclass import OneVsOneClassifier\n","\n","model = OneVsOneClassifier(LogisticRegression(max_iter=200))\n","model.fit(X_train, y_train)\n","\n","# Predict and evaluate\n","y_pred = model.predict(X_test)\n","print(\"One-vs-One (OvO) Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"id":"TVjwtn-ER6Wx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.11) Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification."],"metadata":{"id":"JHUPlw1aR6Gh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Train Logistic Regression\n","model = LogisticRegression(max_iter=200)\n","model.fit(X_train, y_train)\n","\n","# Predict and compute confusion matrix\n","y_pred = model.predict(X_test)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Plot confusion matrix\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n"],"metadata":{"id":"o1Pw_tY5SMiK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.12) Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score."],"metadata":{"id":"6ukr-W1kSMXi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","y_pred = model.predict(X_test)\n","\n","print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n","print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n","print(\"F1-Score:\", f1_score(y_test, y_pred, average='weighted'))\n"],"metadata":{"id":"2aZDQPWYSMTh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.13) Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance."],"metadata":{"id":"fePRjZyOSMOJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) model = LogisticRegression(class_weight='balanced', max_iter=200)\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"id":"_LX1yidoSMKJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.14)  Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance."],"metadata":{"id":"KtYlSp5jSMGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) import pandas as pd\n","from sklearn.impute import SimpleImputer\n","\n","df = pd.read_csv(\"titanic.csv\")\n","\n","# Handling missing values\n","imputer = SimpleImputer(strategy='mean')\n","df.fillna(df.mean(), inplace=True)\n","\n","X = df.drop(columns=['Survived'])\n","y = df['Survived']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","model = LogisticRegression(max_iter=200)\n","model.fit(X_train, y_train)\n","\n","print(\"Titanic Dataset Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"],"metadata":{"id":"5okPLgVjSMCx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.15) Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling."],"metadata":{"id":"O03sqb1aSL-5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","model = LogisticRegression(max_iter=200)\n","model.fit(X_train_scaled, y_train)\n","\n","print(\"Standardized Data Accuracy:\", accuracy_score(y_test, model.predict(X_test_scaled)))\n"],"metadata":{"id":"yabpre3QSL7K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.16)  Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score."],"metadata":{"id":"9B-fvLeASL3Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.metrics import roc_auc_score\n","\n","y_prob = model.predict_proba(X_test)[:, 1]  # Get probability scores\n","print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n"],"metadata":{"id":"rWaZq4utSLzZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.17) Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy."],"metadata":{"id":"Y2CNfPptSLwB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) model = LogisticRegression(C=0.5, max_iter=200)\n","model.fit(X_train, y_train)\n","\n","print(\"Custom Learning Rate Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"],"metadata":{"id":"UEhW65ssSLsZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.18) Write a Python program to train Logistic Regression and identify important features based on model coefficients."],"metadata":{"id":"uKHUD_gHSLoc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) import numpy as np\n","\n","model.fit(X_train, y_train)\n","feature_importance = np.abs(model.coef_)\n","\n","print(\"Feature Importance:\", feature_importance)\n"],"metadata":{"id":"FRfw6FCuSLjx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.19) Write a Python program to train Logistic Regression and evaluate its performance using Cohen's Kappa Score."],"metadata":{"id":"tuN8MWvpSLdR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.metrics import cohen_kappa_score\n","\n","print(\"Cohen's Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n"],"metadata":{"id":"txpcKny-TxQC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.20) Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification."],"metadata":{"id":"h2andDXITxFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.metrics import precision_recall_curve\n","\n","precision, recall, _ = precision_recall_curve(y_test, y_prob)\n","\n","plt.plot(recall, precision, marker='.')\n","plt.xlabel(\"Recall\")\n","plt.ylabel(\"Precision\")\n","plt.title(\"Precision-Recall Curve\")\n","plt.show()\n"],"metadata":{"id":"U8mx4xyETw-T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.21) Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy."],"metadata":{"id":"y3YQzH07Tw4y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) solvers = ['liblinear', 'saga', 'lbfgs']\n","for solver in solvers:\n","    model = LogisticRegression(solver=solver, max_iter=200)\n","    model.fit(X_train, y_train)\n","    print(f\"Accuracy with {solver} solver:\", accuracy_score(y_test, model.predict(X_test)))\n"],"metadata":{"id":"Q54OkDkeT6w6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.22) Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)."],"metadata":{"id":"HJXJMMG-T6oK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.metrics import matthews_corrcoef\n","\n","print(\"Matthews Correlation Coefficient (MCC):\", matthews_corrcoef(y_test, y_pred))\n"],"metadata":{"id":"wy3-qsDlT6bp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.23) Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling."],"metadata":{"id":"E7DEukCIT6SB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) model.fit(X_train, y_train)\n","accuracy_raw = accuracy_score(y_test, model.predict(X_test))\n","\n","model.fit(X_train_scaled, y_train)\n","accuracy_scaled = accuracy_score(y_test, model.predict(X_test_scaled))\n","\n","print(\"Raw Data Accuracy:\", accuracy_raw)\n","print(\"Standardized Data Accuracy:\", accuracy_scaled)\n"],"metadata":{"id":"eCWePRNFUxRZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.24) Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation."],"metadata":{"id":"k005Z_KsUxJi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) from sklearn.model_selection import cross_val_score\n","\n","C_values = [0.01, 0.1, 1, 10]\n","for C in C_values:\n","    model = LogisticRegression(C=C, max_iter=200)\n","    scores = cross_val_score(model, X_train, y_train, cv=5)\n","    print(f\"C={C}, Average Accuracy: {scores.mean()}\")\n"],"metadata":{"id":"CeK93-EbUw5i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.25) Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions."],"metadata":{"id":"uQ8JyamrUwwi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans) import joblib\n","\n","joblib.dump(model, \"logistic_regression_model.pkl\")\n","loaded_model = joblib.load(\"logistic_regression_model.pkl\")\n","\n","y_pred_loaded = loaded_model.predict(X_test)\n","print(\"Loaded Model Accuracy:\", accuracy_score(y_test, y_pred_loaded))\n"],"metadata":{"id":"QojE-Yy2UwlC"},"execution_count":null,"outputs":[]}]}